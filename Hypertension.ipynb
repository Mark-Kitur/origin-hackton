{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4647fb-6099-4672-9626-a484c5c33447",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "The dataset comprises demographic and health-related attributes aimed at predicting the risk of hypertension. Each entry includes information on gender, age, smoking habits (current smoker and cigarettes per day), medication for high blood pressure (BPMeds), presence of diabetes, total cholesterol levels, systolic and diastolic blood pressure, body mass index (BMI), heart rate, glucose levels, and the corresponding hypertension risk label (0 for low risk, 1 for high risk). With a total of 13 features, this dataset provides a comprehensive overview of factors contributing to hypertension, facilitating the development of predictive models for risk assessment and prevention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c22de6-d63b-420c-866e-cdf10434efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec0852a-646b-40a1-9d64-b9b54904de69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  currentSmoker  cigsPerDay  BPMeds  diabetes  totChol  sysBP  \\\n",
       "0        1   39              0         0.0     0.0         0    195.0  106.0   \n",
       "1        0   46              0         0.0     0.0         0    250.0  121.0   \n",
       "2        1   48              1        20.0     0.0         0    245.0  127.5   \n",
       "3        0   61              1        30.0     0.0         0    225.0  150.0   \n",
       "4        0   46              1        23.0     0.0         0    285.0  130.0   \n",
       "...    ...  ...            ...         ...     ...       ...      ...    ...   \n",
       "4235     0   48              1        20.0     NaN         0    248.0  131.0   \n",
       "4236     0   44              1        15.0     0.0         0    210.0  126.5   \n",
       "4237     0   52              0         0.0     0.0         0    269.0  133.5   \n",
       "4238     1   40              0         0.0     0.0         0    185.0  141.0   \n",
       "4239     0   39              1        30.0     0.0         0    196.0  133.0   \n",
       "\n",
       "      diaBP    BMI  heartRate  glucose  Risk  \n",
       "0      70.0  26.97       80.0     77.0     0  \n",
       "1      81.0  28.73       95.0     76.0     0  \n",
       "2      80.0  25.34       75.0     70.0     0  \n",
       "3      95.0  28.58       65.0    103.0     1  \n",
       "4      84.0  23.10       85.0     85.0     0  \n",
       "...     ...    ...        ...      ...   ...  \n",
       "4235   72.0  22.00       84.0     86.0     0  \n",
       "4236   87.0  19.16       86.0      NaN     0  \n",
       "4237   83.0  21.47       80.0    107.0     0  \n",
       "4238   98.0  25.60       67.0     72.0     1  \n",
       "4239   86.0  20.91       85.0     80.0     0  \n",
       "\n",
       "[4240 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"E:\\data sciences\\origin\\origin-hackton\\Hypertension-risk-model-main.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16970cc1-fd2a-457f-9063-257696bb1229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4240 entries, 0 to 4239\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   male           4240 non-null   int64  \n",
      " 1   age            4240 non-null   int64  \n",
      " 2   currentSmoker  4240 non-null   int64  \n",
      " 3   cigsPerDay     4211 non-null   float64\n",
      " 4   BPMeds         4187 non-null   float64\n",
      " 5   diabetes       4240 non-null   int64  \n",
      " 6   totChol        4190 non-null   float64\n",
      " 7   sysBP          4240 non-null   float64\n",
      " 8   diaBP          4240 non-null   float64\n",
      " 9   BMI            4221 non-null   float64\n",
      " 10  heartRate      4239 non-null   float64\n",
      " 11  glucose        3852 non-null   float64\n",
      " 12  Risk           4240 non-null   int64  \n",
      "dtypes: float64(8), int64(5)\n",
      "memory usage: 430.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2464f988-ec1e-4a89-ae75-c121044c5623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4211.000000</td>\n",
       "      <td>4187.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4221.000000</td>\n",
       "      <td>4239.000000</td>\n",
       "      <td>3852.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429245</td>\n",
       "      <td>49.580189</td>\n",
       "      <td>0.494104</td>\n",
       "      <td>9.005937</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>236.699523</td>\n",
       "      <td>132.354599</td>\n",
       "      <td>82.897759</td>\n",
       "      <td>25.800801</td>\n",
       "      <td>75.878981</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>0.310613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495027</td>\n",
       "      <td>8.572942</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>11.922462</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>44.591284</td>\n",
       "      <td>22.033300</td>\n",
       "      <td>11.910394</td>\n",
       "      <td>4.079840</td>\n",
       "      <td>12.025348</td>\n",
       "      <td>23.954335</td>\n",
       "      <td>0.462799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              male          age  currentSmoker   cigsPerDay       BPMeds  \\\n",
       "count  4240.000000  4240.000000    4240.000000  4211.000000  4187.000000   \n",
       "mean      0.429245    49.580189       0.494104     9.005937     0.029615   \n",
       "std       0.495027     8.572942       0.500024    11.922462     0.169544   \n",
       "min       0.000000    32.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000    42.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    49.000000       0.000000     0.000000     0.000000   \n",
       "75%       1.000000    56.000000       1.000000    20.000000     0.000000   \n",
       "max       1.000000    70.000000       1.000000    70.000000     1.000000   \n",
       "\n",
       "          diabetes      totChol        sysBP        diaBP          BMI  \\\n",
       "count  4240.000000  4190.000000  4240.000000  4240.000000  4221.000000   \n",
       "mean      0.025708   236.699523   132.354599    82.897759    25.800801   \n",
       "std       0.158280    44.591284    22.033300    11.910394     4.079840   \n",
       "min       0.000000   107.000000    83.500000    48.000000    15.540000   \n",
       "25%       0.000000   206.000000   117.000000    75.000000    23.070000   \n",
       "50%       0.000000   234.000000   128.000000    82.000000    25.400000   \n",
       "75%       0.000000   263.000000   144.000000    90.000000    28.040000   \n",
       "max       1.000000   696.000000   295.000000   142.500000    56.800000   \n",
       "\n",
       "         heartRate      glucose         Risk  \n",
       "count  4239.000000  3852.000000  4240.000000  \n",
       "mean     75.878981    81.963655     0.310613  \n",
       "std      12.025348    23.954335     0.462799  \n",
       "min      44.000000    40.000000     0.000000  \n",
       "25%      68.000000    71.000000     0.000000  \n",
       "50%      75.000000    78.000000     0.000000  \n",
       "75%      83.000000    87.000000     1.000000  \n",
       "max     143.000000   394.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cba70c-4edd-4db7-b0e7-68a290c18b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "currentSmoker      0\n",
       "cigsPerDay        29\n",
       "BPMeds            53\n",
       "diabetes           0\n",
       "totChol           50\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI               19\n",
       "heartRate          1\n",
       "glucose          388\n",
       "Risk               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a6cefa-b97e-4c25-a941-ede2ac23afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to x and y\n",
    "x = df.drop(\"Risk\",axis=1)\n",
    "y = df[\"Risk\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f3c70b-6842-4e4e-813d-8a4138f8ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  currentSmoker  cigsPerDay  BPMeds  diabetes  totChol  sysBP  \\\n",
       "0        1   39              0         0.0     0.0         0    195.0  106.0   \n",
       "1        0   46              0         0.0     0.0         0    250.0  121.0   \n",
       "2        1   48              1        20.0     0.0         0    245.0  127.5   \n",
       "3        0   61              1        30.0     0.0         0    225.0  150.0   \n",
       "4        0   46              1        23.0     0.0         0    285.0  130.0   \n",
       "...    ...  ...            ...         ...     ...       ...      ...    ...   \n",
       "4235     0   48              1        20.0     NaN         0    248.0  131.0   \n",
       "4236     0   44              1        15.0     0.0         0    210.0  126.5   \n",
       "4237     0   52              0         0.0     0.0         0    269.0  133.5   \n",
       "4238     1   40              0         0.0     0.0         0    185.0  141.0   \n",
       "4239     0   39              1        30.0     0.0         0    196.0  133.0   \n",
       "\n",
       "      diaBP    BMI  heartRate  glucose  \n",
       "0      70.0  26.97       80.0     77.0  \n",
       "1      81.0  28.73       95.0     76.0  \n",
       "2      80.0  25.34       75.0     70.0  \n",
       "3      95.0  28.58       65.0    103.0  \n",
       "4      84.0  23.10       85.0     85.0  \n",
       "...     ...    ...        ...      ...  \n",
       "4235   72.0  22.00       84.0     86.0  \n",
       "4236   87.0  19.16       86.0      NaN  \n",
       "4237   83.0  21.47       80.0    107.0  \n",
       "4238   98.0  25.60       67.0     72.0  \n",
       "4239   86.0  20.91       85.0     80.0  \n",
       "\n",
       "[4240 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4af8ea-f450-428b-9183-25063ae8c4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'diabetes',\n",
       "       'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b455e43-5179-490e-9193-4f45f1783e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    " \n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "#Define the columns\n",
    "num_features = ['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'diabetes',\n",
    "       'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
    "#Create an imputer (simething that fills the missing data)\n",
    "imputer=ColumnTransformer(transformers=[(\"num_imputer\", num_imputer, num_features)])\n",
    "\n",
    "#Transform the data\n",
    "filled_x = imputer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea12ecb-ac94-4577-90f0-77d08bb3537a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,  39.  ,   0.  , ...,  26.97,  80.  ,  77.  ],\n",
       "       [  0.  ,  46.  ,   0.  , ...,  28.73,  95.  ,  76.  ],\n",
       "       [  1.  ,  48.  ,   1.  , ...,  25.34,  75.  ,  70.  ],\n",
       "       ...,\n",
       "       [  0.  ,  52.  ,   0.  , ...,  21.47,  80.  , 107.  ],\n",
       "       [  1.  ,  40.  ,   0.  , ...,  25.6 ,  67.  ,  72.  ],\n",
       "       [  0.  ,  39.  ,   1.  , ...,  20.91,  85.  ,  80.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9972c0e8-06e5-4783-8ca4-f2d8589b12e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male   age  currentSmoker  cigsPerDay  BPMeds  diabetes  totChol  sysBP  \\\n",
       "0      1.0  39.0            0.0         0.0     0.0       0.0    195.0  106.0   \n",
       "1      0.0  46.0            0.0         0.0     0.0       0.0    250.0  121.0   \n",
       "2      1.0  48.0            1.0        20.0     0.0       0.0    245.0  127.5   \n",
       "3      0.0  61.0            1.0        30.0     0.0       0.0    225.0  150.0   \n",
       "4      0.0  46.0            1.0        23.0     0.0       0.0    285.0  130.0   \n",
       "...    ...   ...            ...         ...     ...       ...      ...    ...   \n",
       "4235   0.0  48.0            1.0        20.0     0.0       0.0    248.0  131.0   \n",
       "4236   0.0  44.0            1.0        15.0     0.0       0.0    210.0  126.5   \n",
       "4237   0.0  52.0            0.0         0.0     0.0       0.0    269.0  133.5   \n",
       "4238   1.0  40.0            0.0         0.0     0.0       0.0    185.0  141.0   \n",
       "4239   0.0  39.0            1.0        30.0     0.0       0.0    196.0  133.0   \n",
       "\n",
       "      diaBP    BMI  heartRate  glucose  \n",
       "0      70.0  26.97       80.0     77.0  \n",
       "1      81.0  28.73       95.0     76.0  \n",
       "2      80.0  25.34       75.0     70.0  \n",
       "3      95.0  28.58       65.0    103.0  \n",
       "4      84.0  23.10       85.0     85.0  \n",
       "...     ...    ...        ...      ...  \n",
       "4235   72.0  22.00       84.0     86.0  \n",
       "4236   87.0  19.16       86.0     78.0  \n",
       "4237   83.0  21.47       80.0    107.0  \n",
       "4238   98.0  25.60       67.0     72.0  \n",
       "4239   86.0  20.91       85.0     80.0  \n",
       "\n",
       "[4240 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_x_df = pd.DataFrame(filled_x, columns=num_features)\n",
    "filled_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc803e1d-3d22-4623-95e3-c5bdb1c00061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male             0\n",
       "age              0\n",
       "currentSmoker    0\n",
       "cigsPerDay       0\n",
       "BPMeds           0\n",
       "diabetes         0\n",
       "totChol          0\n",
       "sysBP            0\n",
       "diaBP            0\n",
       "BMI              0\n",
       "heartRate        0\n",
       "glucose          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_x_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e229fe09-f18f-4df4-9729-3029213621a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression,Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f698bb4-731a-48df-91b4-7f1ea13c2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training,validating and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "x = filled_x_df\n",
    "# First split: 70% training, 30% temp (which will be split further)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: 50% of the temp data (15% of the original) for validation, and 50% for test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "# x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "#define a dictionary for models\n",
    "models = {\"Logistic Regression\":LogisticRegression(),\n",
    "          \"bc\":BaggingClassifier(),\n",
    "          \"hgbc\":HistGradientBoostingClassifier(),\n",
    "          \"gn\":GaussianNB(),\n",
    "         \"KNN\":KNeighborsClassifier(),\n",
    "          \"Lasso\":Lasso(),\n",
    "         \"Random Forest\": RandomForestClassifier()}\n",
    "#create a def function for fitiing and evaluating the model\n",
    "\n",
    "def fit_and_evaluate(models,x_train,x_test,y_train,y_test):\n",
    "    \"\"\"\n",
    "    fits and evaluates given machine learning models\n",
    "    models = a dict of different machine learning models\n",
    "    x_test = test data (no label)\n",
    "    x_train = train data (no label)\n",
    "    y_test = test data(label)\n",
    "    y_train(label)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create a for loop function for fitting and evaluation\n",
    "    \n",
    "    models_score = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        #fit the model\n",
    "        model.fit(x_train,y_train)\n",
    "        # evaluate the model by appending it to the empty dictionary\n",
    "        models_score[name] = model.score(x_test,y_test)\n",
    "\n",
    "    return models_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975c4dc3-4ca6-4990-b53a-f16851452a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8238993710691824,\n",
       " 'bc': 0.8836477987421384,\n",
       " 'hgbc': 0.9056603773584906,\n",
       " 'gn': 0.8191823899371069,\n",
       " 'KNN': 0.8757861635220126,\n",
       " 'Lasso': 0.4773817912006073,\n",
       " 'Random Forest': 0.89937106918239}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_score = fit_and_evaluate(models,\n",
    "                                x_train=x_train,\n",
    "                                x_test=x_test,\n",
    "                                y_train=y_train,\n",
    "                                y_test=y_test)\n",
    "models_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc36b22a-25a1-43ff-8020-08bd6870d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_comp=pd.DataFrame(models_score,index=[\"accuracy\"])\n",
    "acc_comp.T.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541f464f-6000-4b3c-a6cd-6ceba537b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=200, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END C=1, max_iter=100, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, max_iter=100, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "130 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\birge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.88241309        nan 0.81873919        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.88241309 0.86287879 0.86153654        nan 0.88241309        nan\n",
      "        nan 0.8211052 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=HistGradientBoostingClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;l2_regularization&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        &#x27;max_depth&#x27;: [None, 3, 5, 7],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [10, 20, 50]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=10, estimator=HistGradientBoostingClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;l2_regularization&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        &#x27;max_depth&#x27;: [None, 3, 5, 7],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [10, 20, 50]},\n",
       "                   random_state=42, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HistGradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html\">?<span>Documentation for HistGradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=HistGradientBoostingClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'l2_regularization': array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        'learning_rate': array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                        'max_depth': [None, 3, 5, 7],\n",
       "                                        'max_iter': [100, 200, 300],\n",
       "                                        'min_samples_leaf': [10, 20, 50]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "log_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C':(1, 10),  # Sample values from a uniform distribution\n",
    "    'solver': ['newton-cg', 'lbfgs'],\n",
    "    'max_iter': [100, 200,]\n",
    "}\n",
    "\n",
    "rf_grid = {\n",
    "    'n_estimators': [50, 100, 200],            # Number of trees\n",
    "    'max_depth': [None, 10, 20],           # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],           # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1,5,3],             # Minimum samples required at each leaf\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "}\n",
    "\n",
    "hgbc_grid = {\n",
    "    'learning_rate': np.logspace(-3, 0, 10),  # Small to larger learning rates\n",
    "    'max_iter': [100, 200,300],  # Number of boosting iterations\n",
    "    'max_depth': [None, 3, 5, 7],  # Maximum depth of trees\n",
    "    'min_samples_leaf': [10, 20,50],  # Minimum samples in leaf nodes\n",
    "    'l2_regularization': np.logspace(-3, 0, 10)  # L2 regularization term\n",
    "}\n",
    "\n",
    "#logisticRegression\n",
    "log = RandomizedSearchCV(LogisticRegression(),\n",
    "                                       param_distributions=log_grid,\n",
    "                                       n_iter=20,\n",
    "                                       cv=10,\n",
    "                                       verbose=2)\n",
    "log.fit(x_train,y_train)\n",
    "\n",
    "#RandomForest\n",
    "\n",
    "random_forest = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), \n",
    "    param_distributions=rf_grid, \n",
    "    n_iter=20,  # Number of parameter settings to try\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    verbose=2)\n",
    "\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "#HistGradientBoost\n",
    "hgbc = RandomizedSearchCV(\n",
    "    estimator=HistGradientBoostingClassifier(),\n",
    "    param_distributions=hgbc_grid,\n",
    "    n_iter=20,  # Number of iterations to perform\n",
    "    cv=10,  # 5-fold cross-validation\n",
    "    verbose=2,  # Output the process\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "hgbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2fabefe-7f47-406c-bde4-6ad4cd951334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009433962264151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgbc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55a5aa1c-af97-4c8a-afb4-66b888c88672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930817610062893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5467ced0-045e-4567-9d1c-3272672a91bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962264150943396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e32590-fe31-4191-99ed-1b91018a10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n",
    "\n",
    "def evaluate_preds(y_true, y_preds):\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    \n",
    "    # Use average='weighted' for precision, recall, and f1 score to handle multiclass\n",
    "    precision = precision_score(y_true, y_preds, average='weighted')\n",
    "    recall = recall_score(y_true, y_preds, average='weighted')\n",
    "    f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "    \n",
    "    metric_dict = {\n",
    "        \"accuracy\": round(accuracy, 2),\n",
    "        \"precision\": round(precision, 2),\n",
    "        \"recall\": round(recall, 2),\n",
    "        \"f1\": round(f1, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2b1193-7de7-4cf9-8ab1-c2392bbd5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.57%\n",
      "Precision: 0.91\n",
      "Recall: 0.91\n",
      "F1 Score: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.91, 'recall': 0.91, 'f1': 0.91}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hgbc\n",
    "hgbc = HistGradientBoostingClassifier()\n",
    "hgbc.fit(x_train,y_train)\n",
    "hgbc_y_preds = hgbc.predict(x_test)\n",
    "hgbc_metrics = evaluate_preds(y_test,hgbc_y_preds)\n",
    "hgbc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39bae0c3-d534-48ca-b7b8-d121ff8394b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hgbc_model_for_hypertension.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump,load\n",
    "dump(hgbc,filename=\"hgbc_model_for_hypertension.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dfd9315-39e8-45d3-8c1f-d65b18a9c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.57%\n",
      "Precision: 0.91\n",
      "Recall: 0.91\n",
      "F1 Score: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.91, 'recall': 0.91, 'f1': 0.91}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_hgbc_model=load(filename=\"hgbc_model_for_hypertension.joblib\")\n",
    "load_hgbc_y_preds = load_hgbc_model.predict(x_test)\n",
    "evaluate_preds(y_test,load_hgbc_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5afc24-25c4-4504-a099-a88a7767e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
